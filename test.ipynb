{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 36, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 读取.pt文件\n",
    "file_path = '/home/langsplat_ws/myfeature-3dgs/feature-3dgs/datasets/isaac_south/sam_embeddings/0000-color_fmap_CxHxW.pt'  # 替换为你的.pt文件路径\n",
    "data = torch.load(file_path)\n",
    "\n",
    "# 输出数据内容\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 1268, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "a = cv2.imread(\"/home/langsplat_ws/myfeature-3dgs/feature-3dgs/datasets/isaac_south/images/0000-color.jpg\")\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sam_model_registry, SamPredictor\n\u001b[0;32m----> 3\u001b[0m sam \u001b[38;5;241m=\u001b[39m \u001b[43msam_model_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvit_h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/langsplat_ws/myfeature-3dgs/feature-3dgs/encoders/sam_encoder/ckpts/sam_vit_h_4b8939.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sam\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m predictor \u001b[38;5;241m=\u001b[39m SamPredictor(sam)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/segment_anything/build_sam.py:15\u001b[0m, in \u001b[0;36mbuild_sam_vit_h\u001b[0;34m(checkpoint)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_sam_vit_h\u001b[39m(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_sam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_embed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_num_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_global_attn_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/segment_anything/build_sam.py:67\u001b[0m, in \u001b[0;36m_build_sam\u001b[0;34m(encoder_embed_dim, encoder_depth, encoder_num_heads, encoder_global_attn_indexes, checkpoint)\u001b[0m\n\u001b[1;32m     64\u001b[0m vit_patch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m     65\u001b[0m image_embedding_size \u001b[38;5;241m=\u001b[39m image_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m vit_patch_size\n\u001b[1;32m     66\u001b[0m sam \u001b[38;5;241m=\u001b[39m Sam(\n\u001b[0;32m---> 67\u001b[0m     image_encoder\u001b[38;5;241m=\u001b[39m\u001b[43mImageEncoderViT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_embed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_num_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvit_patch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_rel_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_attn_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_global_attn_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     81\u001b[0m     prompt_encoder\u001b[38;5;241m=\u001b[39mPromptEncoder(\n\u001b[1;32m     82\u001b[0m         embed_dim\u001b[38;5;241m=\u001b[39mprompt_embed_dim,\n\u001b[1;32m     83\u001b[0m         image_embedding_size\u001b[38;5;241m=\u001b[39m(image_embedding_size, image_embedding_size),\n\u001b[1;32m     84\u001b[0m         input_image_size\u001b[38;5;241m=\u001b[39m(image_size, image_size),\n\u001b[1;32m     85\u001b[0m         mask_in_chans\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     86\u001b[0m     ),\n\u001b[1;32m     87\u001b[0m     mask_decoder\u001b[38;5;241m=\u001b[39mMaskDecoder(\n\u001b[1;32m     88\u001b[0m         num_multimask_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     89\u001b[0m         transformer\u001b[38;5;241m=\u001b[39mTwoWayTransformer(\n\u001b[1;32m     90\u001b[0m             depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     91\u001b[0m             embedding_dim\u001b[38;5;241m=\u001b[39mprompt_embed_dim,\n\u001b[1;32m     92\u001b[0m             mlp_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m,\n\u001b[1;32m     93\u001b[0m             num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     94\u001b[0m         ),\n\u001b[1;32m     95\u001b[0m         transformer_dim\u001b[38;5;241m=\u001b[39mprompt_embed_dim,\n\u001b[1;32m     96\u001b[0m         iou_head_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     97\u001b[0m         iou_head_hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     98\u001b[0m     ),\n\u001b[1;32m     99\u001b[0m     pixel_mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m123.675\u001b[39m, \u001b[38;5;241m116.28\u001b[39m, \u001b[38;5;241m103.53\u001b[39m],\n\u001b[1;32m    100\u001b[0m     pixel_std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m58.395\u001b[39m, \u001b[38;5;241m57.12\u001b[39m, \u001b[38;5;241m57.375\u001b[39m],\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m sam\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/segment_anything/modeling/image_encoder.py:74\u001b[0m, in \u001b[0;36mImageEncoderViT.__init__\u001b[0;34m(self, img_size, patch_size, in_chans, embed_dim, depth, num_heads, mlp_ratio, out_chans, qkv_bias, norm_layer, act_layer, use_abs_pos, use_rel_pos, rel_pos_zero_init, window_size, global_attn_indexes)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(depth):\n\u001b[0;32m---> 74\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlp_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqkv_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mact_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_rel_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_rel_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_pos_zero_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_pos_zero_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mglobal_attn_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\u001b[38;5;241m.\u001b[39mappend(block)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     89\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\n\u001b[1;32m     90\u001b[0m         embed_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m     LayerNorm2d(out_chans),\n\u001b[1;32m    104\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/segment_anything/modeling/image_encoder.py:162\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, dim, num_heads, mlp_ratio, qkv_bias, norm_layer, act_layer, use_rel_pos, rel_pos_zero_init, window_size, input_size)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m Attention(\n\u001b[1;32m    153\u001b[0m     dim,\n\u001b[1;32m    154\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39mnum_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size \u001b[38;5;28;01mif\u001b[39;00m window_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (window_size, window_size),\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2 \u001b[38;5;241m=\u001b[39m norm_layer(dim)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mMLPBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m=\u001b[39m window_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"/home/langsplat_ws/myfeature-3dgs/feature-3dgs/encoders/sam_encoder/ckpts/sam_vit_h_4b8939.pth\")\n",
    "sam.to(\"cuda\")\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "image = a # (1423, 1908, 3)\n",
    "predictor.set_image(image)\n",
    "image_embedding_tensor = torch.tensor(predictor.get_image_embedding().cpu().numpy()[0])\n",
    "image_embedding_tensor.shape\n",
    "img_h, img_w, _ = image.shape   #714,1268\n",
    "_, fea_h, fea_w = image_embedding_tensor.shape # 64，64\n",
    "cropped_h = int(fea_w / img_w * img_h + 0.5)    # 对h做切分，因为一般都是h<w\n",
    "image_embedding_tensor_cropped = image_embedding_tensor[:, :cropped_h, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0445, -0.0878, -0.0702,  ...,  0.1019,  0.1023,  0.1280],\n",
       "         [-0.0904, -0.1353, -0.1231,  ...,  0.0738,  0.0696,  0.0848],\n",
       "         [-0.1177, -0.1539, -0.1491,  ...,  0.0332,  0.0278,  0.0563],\n",
       "         ...,\n",
       "         [-0.0295, -0.0541, -0.0544,  ..., -0.1119, -0.1095, -0.1167],\n",
       "         [-0.0383, -0.0596, -0.0578,  ..., -0.1100, -0.1088, -0.1146],\n",
       "         [-0.0655, -0.0715, -0.0696,  ..., -0.0994, -0.0962, -0.0880]],\n",
       "\n",
       "        [[ 0.1109,  0.0783,  0.0760,  ..., -0.0082, -0.0018,  0.0012],\n",
       "         [ 0.0793,  0.0375,  0.0318,  ..., -0.0642, -0.0475, -0.0059],\n",
       "         [ 0.1126,  0.0623,  0.0468,  ..., -0.0312, -0.0194,  0.0296],\n",
       "         ...,\n",
       "         [ 0.0361,  0.0388,  0.0395,  ...,  0.0985,  0.1001,  0.0752],\n",
       "         [ 0.0435,  0.0465,  0.0490,  ...,  0.1012,  0.1018,  0.0772],\n",
       "         [ 0.0340,  0.0601,  0.0630,  ...,  0.1053,  0.1023,  0.0842]],\n",
       "\n",
       "        [[-0.0170, -0.0046, -0.0094,  ...,  0.0050,  0.0075,  0.0054],\n",
       "         [-0.0293, -0.0162, -0.0240,  ..., -0.0237, -0.0271, -0.0076],\n",
       "         [ 0.0068,  0.0154,  0.0167,  ...,  0.0190,  0.0044,  0.0157],\n",
       "         ...,\n",
       "         [ 0.1039,  0.1488,  0.1505,  ...,  0.2220,  0.2168,  0.2167],\n",
       "         [ 0.1128,  0.1587,  0.1622,  ...,  0.2217,  0.2146,  0.2148],\n",
       "         [ 0.1280,  0.1808,  0.1795,  ...,  0.2150,  0.2100,  0.2166]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0023, -0.0023, -0.0024,  ..., -0.0023, -0.0023, -0.0022],\n",
       "         [-0.0024, -0.0024, -0.0024,  ..., -0.0024, -0.0024, -0.0023],\n",
       "         [-0.0024, -0.0025, -0.0025,  ..., -0.0024, -0.0024, -0.0023],\n",
       "         ...,\n",
       "         [-0.0022, -0.0022, -0.0022,  ..., -0.0023, -0.0023, -0.0023],\n",
       "         [-0.0022, -0.0022, -0.0022,  ..., -0.0023, -0.0024, -0.0023],\n",
       "         [-0.0021, -0.0022, -0.0022,  ..., -0.0023, -0.0023, -0.0024]],\n",
       "\n",
       "        [[ 0.0099,  0.0596,  0.0651,  ...,  0.0896,  0.0869,  0.0555],\n",
       "         [ 0.0539,  0.1082,  0.1179,  ...,  0.1337,  0.1325,  0.1115],\n",
       "         [ 0.0717,  0.1214,  0.1260,  ...,  0.1482,  0.1535,  0.1298],\n",
       "         ...,\n",
       "         [ 0.3368,  0.3413,  0.3420,  ...,  0.1737,  0.1617,  0.1284],\n",
       "         [ 0.3183,  0.3190,  0.3191,  ...,  0.1607,  0.1531,  0.1212],\n",
       "         [ 0.2921,  0.3063,  0.2950,  ...,  0.1512,  0.1492,  0.1358]],\n",
       "\n",
       "        [[ 0.0641,  0.1285,  0.1071,  ...,  0.0537,  0.0518,  0.0407],\n",
       "         [ 0.0275,  0.0664,  0.0504,  ..., -0.0147, -0.0180, -0.0164],\n",
       "         [ 0.0326,  0.0711,  0.0611,  ...,  0.0049, -0.0040, -0.0087],\n",
       "         ...,\n",
       "         [ 0.0204,  0.0588,  0.0567,  ..., -0.0190, -0.0274, -0.0436],\n",
       "         [-0.0007,  0.0437,  0.0429,  ..., -0.0266, -0.0352, -0.0489],\n",
       "         [-0.0784, -0.0126, -0.0069,  ..., -0.0486, -0.0573, -0.0644]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embedding_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
